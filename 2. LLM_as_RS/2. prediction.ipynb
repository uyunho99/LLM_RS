{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 예측 전 확인해야 할 사항\n",
    "\n",
    "# 모델 GPU 성능에 맞춰서 batch_size, new_prompt_1의 numb을 조정해야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import tqdm as notebook_tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datasets\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, pipeline, logging, Trainer\n",
    "\n",
    "from peft import LoraConfig\n",
    "from trl import SFTTrainer\n",
    "\n",
    "# Huggingface에서 LLaMA 모델 권한 신청 이후, 권한 신청한 계정의 토큰을 [your token]에 입력\n",
    "subprocess.run([\"huggingface-cli\", \"login\", \"--token\", \"[your token]\"])\n",
    "\n",
    "with open(file='/data/log-data-2024/prompt_data.pickle', mode='rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "# Model\n",
    "torch_dtype = torch.float16\n",
    "    \n",
    "model_ckpt = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch_dtype,\n",
    "    bnb_4bit_use_double_quant=False\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n",
    "print(tokenizer.eos_token, tokenizer.eos_token_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_ckpt,\n",
    "    low_cpu_mem_usage=True,\n",
    "    quantization_config=bnb_config,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device_map='auto'\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "\n",
    "# Dataset\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "train_dataset = datasets.Dataset.from_dict({key: [item[key] for item in train_data] for key in train_data[0]})\n",
    "test_dataset = datasets.Dataset.from_dict({key: [item[key] for item in test_data] for key in test_data[0]})\n",
    "\n",
    "# Tokenizing\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    inputs = tokenizer(examples[\"prompt\"], padding=\"max_length\", truncation=True, max_length=200) # 200까지 줄여도 될듯\n",
    "    outputs = tokenizer(examples[\"completion\"], padding=\"max_length\", truncation=True, max_length=20) # 20까지 줄여도 될듯\n",
    "    inputs[\"labels\"] = outputs[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate token lengths for each dataset\n",
    "train_input_lengths = [len(tokenizer(example['prompt'], truncation=True, max_length=500)[\"input_ids\"]) for example in train_data]\n",
    "train_output_lengths = [len(tokenizer(example['completion'], truncation=True, max_length=50)[\"input_ids\"]) for example in train_data]\n",
    "\n",
    "test_input_lengths = [len(tokenizer(example['prompt'], truncation=True, max_length=500)[\"input_ids\"]) for example in test_data]\n",
    "test_output_lengths = [len(tokenizer(example['completion'], truncation=True, max_length=50)[\"input_ids\"]) for example in test_data]\n",
    "\n",
    "# Plot histograms for train dataset\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_input_lengths, bins=30, edgecolor='black')\n",
    "plt.title('Train Dataset Input Lengths')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(train_output_lengths, bins=30, edgecolor='black')\n",
    "plt.title('Train Dataset Output Lengths')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot histograms for test dataset\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(test_input_lengths, bins=30, edgecolor='black')\n",
    "plt.title('Test Dataset Input Lengths')\n",
    "plt.xlabel('Token Length')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(test_output_lengths, bins=30, edgecolor='black')\n",
    "plt.title('Test Dataset Output Lengths')\n",
    "plt.xlabel('Token Length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python prediction.py"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
