{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "os.getcwd()\n",
    "tqdm.pandas()\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.llms import LlamaCpp, Ollama\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.callbacks import CallbackManager, StreamingStdOutCallbackHandler\n",
    "\n",
    "sequence = pd.read_csv(\"/data/log-data-2024/SASRec/BSARec/src/data/input_search_sample_matching_final.txt\") # past squence\n",
    "match = pd.read_csv(\"/data/log-data-2024/1.meta_rot_preprocessing_ksc/data/Meta_V3.csv\")\n",
    "match = dict(zip(match[\"contents_id\"], match[\"title_name\"]))\n",
    "\n",
    "samp = list(pd.read_csv(\"/data/log-data-2024/8man_sample_new_new.csv\")[\"treatment2\"]) # 1st sampling\n",
    "sequence[\"use\"] = [1 if i in samp else 0 for i in sequence[\"device_id\"]]\n",
    "sequence = sequence[sequence[\"use\"] == 1].reset_index(drop = True)\n",
    "\n",
    "with open(file='/data/log-data-2024/2.sequence_generate_ksc/data/content_meta_dict_final.pickle', mode='rb') as f:\n",
    "    met = pickle.load(f) # meta\n",
    "\n",
    "meta = {}\n",
    "for i in met:\n",
    "    meta[i.split(\". \")[1]] = met[i]\n",
    "\n",
    "samp = pd.read_csv(\"/data/log-data-2024/8man_sample_20241022_treatment2.csv\") # 2nd sampling\n",
    "samp[\"treatment2 prediction content_id\"] = samp[\"treatment2 prediction content_id\"].apply(lambda x : ast.literal_eval(x))\n",
    "matched_samp = list(samp[\"treatment2\"])\n",
    "prediction = list(samp[\"treatment2 prediction content_id\"])\n",
    "sequence[\"use\"] = [1 if i in matched_samp else 0 for i in sequence[\"device_id\"]]\n",
    "sequence = sequence[sequence[\"use\"] == 1].reset_index(drop = True)\n",
    "\n",
    "sequence[\"sequence\"] = [i.split()[1:] for i in sequence[\"sequence\"]]\n",
    "sequence = dict(zip(sequence[\"device_id\"], sequence[\"sequence\"]))\n",
    "samp[\"sequence\"] = [sequence[i] for i in samp[\"treatment2\"]]\n",
    "\n",
    "samp = samp[[\"treatment2\", \"treatment2 prediction content_id\", \"sequence\"]]\n",
    "samp.columns = [\"device_id\", \"prediction\", \"sequence\"]\n",
    "\n",
    "tt = []\n",
    "for i in samp[\"prediction\"]:\n",
    "    ttt = []\n",
    "    for w in i:\n",
    "        ttt.append(match[w])\n",
    "    tt.append(ttt)\n",
    "samp[\"prediction\"] = tt\n",
    "    \n",
    "sequence = samp.copy()\n",
    "\n",
    "movie_meta = pd.read_csv(\"/data/meta/us_vod_metadata_movie.csv\")\n",
    "show_meta = pd.read_csv(\"/data/meta/us_vod_metadata_tvshow.csv\")\n",
    "\n",
    "movie_meta = movie_meta[[\"title_name\", \"age_code\"]]\n",
    "show_meta = show_meta[[\"title_name\", \"age_code\"]]\n",
    "add_meta = pd.concat([movie_meta, show_meta], axis = 0).reset_index(drop = True)\n",
    "\n",
    "add_meta[\"title_name\"] = add_meta[\"title_name\"].apply(lambda x : x.upper())\n",
    "add_meta[\"age_code\"] = [\"ALL\" if i < 18 else \"R19\" for i in add_meta[\"age_code\"]]\n",
    "tn = dict(zip(add_meta[\"title_name\"], add_meta[\"age_code\"]))\n",
    "\n",
    "for i in meta:\n",
    "    try:\n",
    "        meta[i] = meta[i][:-1] + \", age: {}\".format(tn[i])\n",
    "    except:\n",
    "        pass\n",
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = re.compile(\"genre_info: \\[.+\\], actor_info\")\n",
    "genres = []\n",
    "for i in meta:\n",
    "    try:\n",
    "        temp = z.findall(meta[i])[0][13:-13].split(\", \")\n",
    "        for w in temp:\n",
    "            genres.append(w)\n",
    "    except:\n",
    "        pass\n",
    "genres = list(set(genres))\n",
    "genre_list = []\n",
    "for i in genres:\n",
    "    genre_list.append(i)\n",
    "    genre_list.append(i.title())\n",
    "genre_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "met = {}\n",
    "\n",
    "for i in tqdm(meta):\n",
    "    temp = i.split(\". \")\n",
    "    if len(temp) == 2:\n",
    "        met[temp[0]] = \"title: \" + temp[1] + \", \" + meta[i]\n",
    "    else:\n",
    "        met[temp[0]] = \"title: \" + \" \".join(temp[1:]) + \", \" + meta[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OLLAMA_LLM_LIBRARY\"] = \"cpu_avx2\"\n",
    "\n",
    "# model_name = 'llama3.1:70b'\n",
    "model_name = 'llama3.1'\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "llm = Ollama(\n",
    "    model=model_name,\n",
    "    temperature=0.75,\n",
    "    verbose=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = []\n",
    "temp2 = []\n",
    "for a, i in enumerate(sequence[\"sequence\"]):\n",
    "    temp1.append(list(set(sequence[\"prediction\"].loc[a])))\n",
    "    temp2.append(list(set(sequence[\"prediction\"].loc[a])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = []\n",
    "for i in tqdm(temp1):\n",
    "    t2 = {}\n",
    "    for w in i:\n",
    "        try:\n",
    "            t2[w] = met[str(w)]\n",
    "        except:\n",
    "            pass\n",
    "    t1.append(t2)\n",
    "sequence[\"meta\"] = t1\n",
    "\n",
    "t1 = []\n",
    "for i in tqdm(temp2):\n",
    "    t2 = \"ALL\"\n",
    "    for w in i:\n",
    "        try:\n",
    "            if \"R19\" in met[str(w)]:\n",
    "                t2 = \"R19\"\n",
    "        except:\n",
    "            pass\n",
    "    t1.append(t2)\n",
    "sequence[\"meta2\"] = t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import heapq\n",
    "\n",
    "g = []\n",
    "for i in sequence[\"meta\"]:\n",
    "    gen = []\n",
    "    for w in i:\n",
    "        try:\n",
    "            for p in z.findall(i[w])[0][13:-13].split(\", \"):\n",
    "                gen.append(p)\n",
    "        except:\n",
    "            pass\n",
    "    tops = heapq.nlargest(3, dict(Counter(gen)), key=dict(Counter(gen)).get)\n",
    "    top = []\n",
    "    for w in tops:\n",
    "        top.append(w)\n",
    "        top.append(w.title())\n",
    "    g.append(top)\n",
    "sequence[\"major_genre\"] = g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# few-shots\n",
    "exp = pd.read_csv(\"classification.csv\")\n",
    "good_examples = list(exp[exp[\"Rating\"] == 1][\"message\"])[:10]\n",
    "bad_examples = list(exp[exp[\"Rating\"] == 0][\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanse(string):\n",
    "        \n",
    "    r = re.compile('\\\".*?\\\"')\n",
    "    a = re.compile(\".+:\")\n",
    "    \n",
    "    try:\n",
    "        string = r.findall(string)[0]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    string = re.sub(a, \" \", string)\n",
    "    return string.strip()\n",
    "\n",
    "def generate_message(table):\n",
    "    result = []\n",
    "    \n",
    "    system1 = '''\n",
    "    <|begin_of_text|><<|start_header_id|>system<|end_header_id|>\n",
    "    You are a marketing manager responsible to generate recommendation messages for smart TV recommendation system.\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "\n",
    "    user1 = '''\n",
    "    <|begin_of_text|><<|start_header_id|>user<|end_header_id|>\n",
    "    I will provide you \"a squence of contents\" that a specific customer has previously viewed.\n",
    "    Summarize the smart TV contents consumption patterns of the customer in one sentence.\n",
    "    Concentrate on the common points of the contents if possible.\n",
    "    Simply output the summary only.\n",
    "    You should retrieve the \"information of the contents\" to identify which contents are assigned to each number.\n",
    "    A squence of contents: {sequence}\n",
    "    Information of the contents: {meta}.\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "\n",
    "    system2 = '''\n",
    "    <|begin_of_text|><<|start_header_id|>system<|end_header_id|>\n",
    "    You are a marketing manager responsible to generate recommendation messages for smart TV recommendation system.\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "\n",
    "    user2 = '''\n",
    "    <|begin_of_text|><<|start_header_id|>user<|end_header_id|>\n",
    "    Based on the following \"characteristics of a customer\", generate a recommendation message that encourage customers to click-through the recommended contents.\n",
    "    The recommendation message should be a sentence consists of 15 - 60 characters.\n",
    "    The recommended contents are already determined: you should not recommend specific contents or genres.\n",
    "    Focus only on the characteristics of the customer, instead of focusing on the recommended contents.\n",
    "    You should use only general nouns when referring to recommended contents, such as contents, programs, recommendations, and picks.\n",
    "    Any modifier for the recommended contents is strictly prohibited. For example, recommending \"triller contents\" or \"comedy programs\" is not allowed.\n",
    "    Characteristics of the customers: {character}\n",
    "    Simply output one recommendation message only.\n",
    "    Avoid generating similar messages with \"Bad examples\".\n",
    "\n",
    "    Good examples: {good exp}\n",
    "    Bad examples: {bad exp}\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "\n",
    "    for i in tqdm(table.index):\n",
    "\n",
    "        template_text1 = system1 + user1\n",
    "\n",
    "        prompt1 = PromptTemplate.from_template(template_text1)\n",
    "\n",
    "        formatted_inputs1 = {\n",
    "            \"sequence\": table[\"prediction\"].loc[i],\n",
    "            \"meta\": table[\"meta\"].loc[i]\n",
    "        }\n",
    "\n",
    "        chain1 = prompt1 | llm | StrOutputParser()\n",
    "        response1 = chain1.invoke(formatted_inputs1)\n",
    "\n",
    "        # ------------------------------------------------------------------------\n",
    "\n",
    "        template_text2 = system2 + user2\n",
    "\n",
    "        prompt2 = PromptTemplate.from_template(template_text2)\n",
    "\n",
    "        formatted_inputs2 = {\n",
    "            \"character\": response1,\n",
    "            \"good exp\" : good_examples,\n",
    "            \"bad exp\" : bad_examples\n",
    "        }\n",
    "\n",
    "        chain2 = prompt2 | llm | StrOutputParser()\n",
    "        response2 = chain2.invoke(formatted_inputs2)\n",
    "\n",
    "        result.append(response2)\n",
    "        \n",
    "    df = pd.DataFrame({\"device_id\" : table[\"device_id\"], \"message\" : result, \"sequence\" : table[\"sequence\"],\n",
    "                       \"prediction\" : table[\"prediction\"], \"meta\" : table[\"meta\"], \"major_genre\" : table[\"major_genre\"]})\n",
    "    \n",
    "    df[\"message\"] = df[\"message\"].apply(lambda x : cleanse(x))\n",
    "    return df\n",
    "    \n",
    "def approve_message(table):\n",
    "    \n",
    "    system = '''\n",
    "    <|begin_of_text|><<|start_header_id|>system<|end_header_id|>\n",
    "    You are a classifier.\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "    user = '''\n",
    "    <|begin_of_text|><<|start_header_id|>user<|end_header_id|>\n",
    "    I will provide you a recommendation message. Evaluate whether the message meets the conditions below.\n",
    "    Output \"Approved\" if the message meets all conditions below, otherwise \"Rejected\".\n",
    "    Output the basis of the decision with the decision per condition.\n",
    "    Message: {msg}\n",
    "    Condition 1. The message should not recommend specific contents or genres.\n",
    "    Condition 2. Recommending contents to specific type of customers is allowed.\n",
    "    Condition 3: The message should be grammatically correct and fluent.\n",
    "    Condition 4: The message should be a sentence consists of 15 - 60 characters.\n",
    "    Condition 5. Message recommending family-friendly contents is prohibited if the {meta} is \"R19\".\n",
    "    Do not check other conditions than listed.\n",
    "    Genres are listed in {grs}\n",
    "    <|eot_id|>\n",
    "    '''\n",
    "\n",
    "    template_text = system + user\n",
    "\n",
    "    prompt = PromptTemplate.from_template(template_text)\n",
    "\n",
    "    filtering = []\n",
    "    for i in table.index:\n",
    "        classify = 1\n",
    "        target = table[\"message\"].loc[i]\n",
    "        comp = table[\"major_genre\"].loc[i]\n",
    "        if (\"Thrill\" in target) & (\"thriller\" not in comp):\n",
    "            classify = 0\n",
    "        elif (\"thrill\" in target) & (\"thriller\" not in comp):\n",
    "            classify = 0\n",
    "        else:\n",
    "            compare = list(set(genre_list) - set(comp))\n",
    "\n",
    "            for w in compare:\n",
    "                if w in target:\n",
    "                    classify = 0\n",
    "                    break\n",
    "                else:\n",
    "                    pass\n",
    "        if classify == 1:\n",
    "            filtering.append(1)\n",
    "        else:\n",
    "            filtering.append(0)\n",
    "            \n",
    "    result = []\n",
    "    for a, i in tqdm(enumerate(table.index)):\n",
    "        if filtering[a] == 0:\n",
    "            result.append(0)\n",
    "        else:\n",
    "            formatted_inputs = {\n",
    "                \"msg\" : target,\n",
    "                \"grs\" : genres,\n",
    "                \"meta\": table[\"meta\"].loc[i]\n",
    "            }\n",
    "\n",
    "            chain = prompt | llm | StrOutputParser()\n",
    "            response = chain.invoke(formatted_inputs)\n",
    "\n",
    "            result.append(response)\n",
    "            \n",
    "    table[\"class\"] = result\n",
    "    table[\"class\"] = [0 if i == 0 else 0 if \"Rejected\" in i else 0 if ((\"Rejected\" not in i) & (\"Approved\" not in i)) else 1 for i in table[\"class\"]]\n",
    "    \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns = [\"device_id\", \"message\", \"sequence\", \"prediction\", \"meta\", \"class\"])\n",
    "seq = sequence.copy()\n",
    "df = seq.copy()\n",
    "\n",
    "while len(result.index) != len(seq.index):\n",
    "    df = generate_message(df)\n",
    "    df = approve_message(df)\n",
    "    \n",
    "    approved = df[df[\"class\"] == 1]\n",
    "    df = df[df[\"class\"] == 0]\n",
    "    \n",
    "    bad_examples = list(df[\"message\"].iloc[:10])\n",
    "    \n",
    "    result = pd.concat([result, approved], axis = 0).reset_index(drop = True)\n",
    "    \n",
    "    if len(result.index) > len(sequence.index)/3:\n",
    "        result.to_csv(\"result_20241118_llmemb_able.csv\")\n",
    "        break\n",
    "    \n",
    "result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
