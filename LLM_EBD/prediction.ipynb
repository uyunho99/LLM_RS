{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.sasrec import SASRecModel\n",
    "from trainers import Trainer\n",
    "from utils import EarlyStopping, check_path, set_seed, set_logger\n",
    "from dataset import get_seq_dic, get_dataloder, get_rating_matrix\n",
    "\n",
    "# Set up arguments\n",
    "class Args:\n",
    "    data_dir = \"./data/\"\n",
    "    output_dir = \"output/\"\n",
    "    data_name = \"cleaned_final_20241123\"\n",
    "    do_eval = False\n",
    "    load_model = None\n",
    "    train_name = \"1123_model\"\n",
    "    num_items = 10\n",
    "    num_users = 10\n",
    "    lr = 0.001\n",
    "    batch_size = 1024\n",
    "    epochs = 10\n",
    "    # no_cuda = False\n",
    "    no_cuda = True\n",
    "    log_freq = 1\n",
    "    patience = 2\n",
    "    num_workers = 0  # Set num_workers to 0 to avoid BrokenPipeError on Windows\n",
    "    seed = 42\n",
    "    weight_decay = 0.0\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "    gpu_id = \"0,1,2,3\"\n",
    "    variance = 5\n",
    "    model_type = 'sasrec'\n",
    "#     model_type = 'sasrec_model'\n",
    "    max_seq_length = 10\n",
    "    hidden_size = 128\n",
    "    num_hidden_layers = 2\n",
    "    hidden_act = \"gelu\"\n",
    "    num_attention_heads = 2\n",
    "    attention_probs_dropout_prob = 0.5\n",
    "    hidden_dropout_prob = 0.5\n",
    "    initializer_range = 0.02\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "model = torch.load(\"./llmeb_1123.pt\")\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standalone predict function\n",
    "def predict(model, input_ids, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        recommend_output = model.forward(input_ids, all_sequence_output=False)\n",
    "        recommend_output = recommend_output[:, -1, :]  # Last item in the sequence\n",
    "\n",
    "        test_item_emb = model.item_embeddings.weight.to(device)\n",
    "        rating_pred = torch.matmul(recommend_output, test_item_emb.transpose(0, 1))\n",
    "        rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "\n",
    "        top20_indices = np.argpartition(rating_pred, -40)[:, -40:]\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], top20_indices]\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "        top20_indices = top20_indices[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "\n",
    "    return top20_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_path = '/data/log-data-2024/yh/LLM_EB/src/data/cleaned_final_20241123.txt'\n",
    "with open(input_file_path, 'r') as f:\n",
    "    input_data = f.readlines()\n",
    "\n",
    "input_ids = []\n",
    "for line in input_data:\n",
    "    items = list(map(int, line.strip().split()))\n",
    "    pad_len = args.max_seq_length - len(items)\n",
    "    input_ids.append([0] * pad_len + items)\n",
    "\n",
    "input_ids = []\n",
    "for line in input_data:\n",
    "    items = list(map(int, line.strip().split()))\n",
    "    # Truncate sequences longer than max_seq_length\n",
    "    if len(items) > args.max_seq_length:\n",
    "        items = items[-args.max_seq_length:]\n",
    "    pad_len = args.max_seq_length - len(items)\n",
    "    input_ids.append([0] * pad_len + items)\n",
    "\n",
    "confirm = []\n",
    "for i in tqdm(input_ids):\n",
    "    temp = []\n",
    "    for w in i:\n",
    "        if w != 0:\n",
    "            temp.append(w)\n",
    "    confirm.append(temp)\n",
    "\n",
    "length = [len(i) for i in confirm]\n",
    "print(np.mean(length), np.std(length), np.min(length), np.max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [i[-1] for i in input_ids]\n",
    "input_ids = [i[:-1] for i in input_ids]\n",
    "\n",
    "lab = label[:1000]\n",
    "ids = input_ids[:1000]\n",
    "\n",
    "pred = predict(model, ids, device).tolist() # SASRec 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hr_at_k(recommendations, true_labels, k=20):\n",
    "    score = 0\n",
    "    recommendations = [i[:k] for i in recommendations]\n",
    "    for a, i in enumerate(true_labels):\n",
    "        if i in recommendations[a]:\n",
    "            score += 1\n",
    "    return score/len(true_labels)\n",
    "\n",
    "def precision_at_k(recommendations, true_labels, k=20):\n",
    "    precision_scores = []\n",
    "    \n",
    "    for user_recommendations, true_label in zip(recommendations, true_labels):\n",
    "        # 추천된 상위 20개 중 실제 정답이 있는지 확인\n",
    "        hits = 1 if true_label in user_recommendations[:k] else 0\n",
    "        \n",
    "        # Precision은 정답이 있으면 1 / k, 없으면 0\n",
    "        precision = hits / k\n",
    "        precision_scores.append(precision)\n",
    "    \n",
    "    # 모든 사용자에 대한 평균 Precision을 반환\n",
    "    return sum(precision_scores) / len(precision_scores)\n",
    "\n",
    "def recall_at_k(recommendations, true_labels, k=20):\n",
    "    recall_scores = []\n",
    "    \n",
    "    for user_recommendations, true_label in zip(recommendations, true_labels):\n",
    "        # 추천된 상위 k개 중 실제 정답이 있는지 확인\n",
    "        hits = 1 if true_label in user_recommendations[:k] else 0\n",
    "        \n",
    "        # Recall은 정답이 있으면 1, 없으면 0\n",
    "        recall = hits\n",
    "        recall_scores.append(recall)\n",
    "    \n",
    "    # 모든 사용자에 대한 평균 Recall을 반환\n",
    "    return sum(recall_scores) / len(recall_scores)\n",
    "\n",
    "def total_print(k):\n",
    "    print(\"LLM for Embedding HR@{}: \".format(k), round(hr_at_k(pred, lab, k = k), 3))\n",
    "    print(\"LLM for Embedding precision@{}: \".format(k), round(precision_at_k(pred, lab, k = k), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(total_print(1))\n",
    "print(total_print(3))\n",
    "print(total_print(5))\n",
    "print(total_print(10))\n",
    "print(total_print(15))\n",
    "print(total_print(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "\n",
    "df = pd.read_csv(\"/data/log-data-2024/2.sequence_generate_ksc/data/sequence_device_match_241123.csv\")\n",
    "cf = pd.read_csv(\"/data/log-data-2024/20241123_Final/input_search_final_20241123.txt\", sep = \"\\t\", header = None)\n",
    "df = pd.concat([df, cf], axis = 1)\n",
    "\n",
    "with open(file= '/data/log-data-2024/20241123_Final/match_dict_final.pickle', mode='rb') as f:\n",
    "    dic1 = pickle.load(f)\n",
    "\n",
    "with open(file= '/data/log-data-2024/20241123_Final/match_dict_final2.pickle', mode='rb') as f:\n",
    "    dic2 = pickle.load(f)\n",
    "    \n",
    "samp = list(pd.read_csv(\"/data/log-data-2024/20241123_Final/8man_sample_20241123\")[\"treatment2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev = dict(zip(list(dic1.values()), list(dic1.keys())))\n",
    "dic = {}\n",
    "for i in dic2:\n",
    "    try:\n",
    "        dic[rev[i]] = dic2[i]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "df[\"use\"] = [1 if i in samp else 0 for i in tqdm(df[\"device_id\"])]\n",
    "df = df[df[\"use\"] == 1]\n",
    "df = df.drop_duplicates(subset = 'device_id').reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_file_path = \"/data/log-data-2024/SASRec/BSARec/src/data/input_search_prediction_final.txt\"\n",
    "# with open(input_file_path, 'r') as f:\n",
    "#     input_data = f.readlines()\n",
    "\n",
    "input_data = []\n",
    "\n",
    "for i in df[0]:\n",
    "    temp = []\n",
    "    t = i.split()[1:]\n",
    "    for w in t:\n",
    "#         temp.append(dic[int(w)])\n",
    "        try:\n",
    "            temp.append(dic[int(w)])\n",
    "        except:\n",
    "            pass\n",
    "    input_data.append(\" \".join(temp))\n",
    "\n",
    "input_ids = []\n",
    "for line in input_data:\n",
    "    items = list(map(int, line.strip().split()))\n",
    "    pad_len = args.max_seq_length - len(items)\n",
    "    input_ids.append([0] * pad_len + items)\n",
    "    \n",
    "# confirm = []\n",
    "# for i in tqdm(input_ids):\n",
    "#     temp = []\n",
    "#     for w in i:\n",
    "#         if w != 0:\n",
    "#             temp.append(w)\n",
    "#     confirm.append(temp)\n",
    "\n",
    "# length = [len(i) for i in confirm]\n",
    "# print(np.mean(length), np.std(length), np.min(length), np.max(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = []\n",
    "for i in input_ids:\n",
    "    temp = i\n",
    "    while len(temp) > 50:\n",
    "        temp = temp[1:]\n",
    "    ii.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for i in range(20):\n",
    "    pred = pred + predict(model, ii[i*1000:(i+1)*1000], device).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp = pd.DataFrame({\"treatment2\" : df[\"device_id\"], \"treatment2 prediction\" : pred}).reset_index(drop = True)\n",
    "samp.to_csv(\"/data/log-data-2024/20241123_Final/8man_sample_20241123_predicted_treatment2\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
