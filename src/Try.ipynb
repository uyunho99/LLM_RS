{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3b948ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 15:30:52,765 - <__main__.Args object at 0x1041e21f0>\n",
      "2024-05-29 15:30:52,765 - <__main__.Args object at 0x1041e21f0>\n",
      "2024-05-29 15:30:52,787 - SASRecModel(\n",
      "  (item_embeddings): Embedding(12102, 64, padding_idx=0)\n",
      "  (position_embeddings): Embedding(50, 64)\n",
      "  (LayerNorm): LayerNorm()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (item_encoder): TransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-1): 2 x TransformerBlock(\n",
      "        (layer): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2024-05-29 15:30:52,787 - SASRecModel(\n",
      "  (item_embeddings): Embedding(12102, 64, padding_idx=0)\n",
      "  (position_embeddings): Embedding(50, 64)\n",
      "  (LayerNorm): LayerNorm()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (item_encoder): TransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-1): 2 x TransformerBlock(\n",
      "        (layer): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2024-05-29 15:30:52,788 - Total Parameters: 877824\n",
      "2024-05-29 15:30:52,788 - Total Parameters: 877824\n",
      "Mode_train:0: 100%|| 587/587 [01:27<00:00,  6.72it/s]\n",
      "2024-05-29 15:32:20,190 - {'epoch': 0, 'rec_loss': '1.2361'}\n",
      "2024-05-29 15:32:20,190 - {'epoch': 0, 'rec_loss': '1.2361'}\n",
      "Mode_test:0: 100%|| 88/88 [00:06<00:00, 13.17it/s]\n",
      "2024-05-29 15:32:27,404 - {'Epoch': 0, 'HR@5': '0.0105', 'NDCG@5': '0.0068', 'HR@10': '0.0169', 'NDCG@10': '0.0088', 'HR@20': '0.0296', 'NDCG@20': '0.0120'}\n",
      "2024-05-29 15:32:27,404 - {'Epoch': 0, 'HR@5': '0.0105', 'NDCG@5': '0.0068', 'HR@10': '0.0169', 'NDCG@10': '0.0088', 'HR@20': '0.0296', 'NDCG@20': '0.0120'}\n",
      "2024-05-29 15:32:27,411 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:32:27,411 - Validation score increased.  Saving model ...\n",
      "Mode_train:1: 100%|| 587/587 [01:26<00:00,  6.75it/s]\n",
      "2024-05-29 15:33:54,401 - {'epoch': 1, 'rec_loss': '1.0999'}\n",
      "2024-05-29 15:33:54,401 - {'epoch': 1, 'rec_loss': '1.0999'}\n",
      "Mode_test:1: 100%|| 88/88 [00:06<00:00, 13.34it/s]\n",
      "2024-05-29 15:34:01,536 - {'Epoch': 1, 'HR@5': '0.0141', 'NDCG@5': '0.0089', 'HR@10': '0.0211', 'NDCG@10': '0.0112', 'HR@20': '0.0346', 'NDCG@20': '0.0145'}\n",
      "2024-05-29 15:34:01,536 - {'Epoch': 1, 'HR@5': '0.0141', 'NDCG@5': '0.0089', 'HR@10': '0.0211', 'NDCG@10': '0.0112', 'HR@20': '0.0346', 'NDCG@20': '0.0145'}\n",
      "2024-05-29 15:34:01,545 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:34:01,545 - Validation score increased.  Saving model ...\n",
      "Mode_train:2: 100%|| 587/587 [01:31<00:00,  6.43it/s]\n",
      "2024-05-29 15:35:32,779 - {'epoch': 2, 'rec_loss': '1.0181'}\n",
      "2024-05-29 15:35:32,779 - {'epoch': 2, 'rec_loss': '1.0181'}\n",
      "Mode_test:2: 100%|| 88/88 [00:06<00:00, 12.78it/s]\n",
      "2024-05-29 15:35:40,236 - {'Epoch': 2, 'HR@5': '0.0159', 'NDCG@5': '0.0099', 'HR@10': '0.0283', 'NDCG@10': '0.0139', 'HR@20': '0.0446', 'NDCG@20': '0.0180'}\n",
      "2024-05-29 15:35:40,236 - {'Epoch': 2, 'HR@5': '0.0159', 'NDCG@5': '0.0099', 'HR@10': '0.0283', 'NDCG@10': '0.0139', 'HR@20': '0.0446', 'NDCG@20': '0.0180'}\n",
      "2024-05-29 15:35:40,245 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:35:40,245 - Validation score increased.  Saving model ...\n",
      "Mode_train:3: 100%|| 587/587 [01:31<00:00,  6.40it/s]\n",
      "2024-05-29 15:37:11,983 - {'epoch': 3, 'rec_loss': '0.9504'}\n",
      "2024-05-29 15:37:11,983 - {'epoch': 3, 'rec_loss': '0.9504'}\n",
      "Mode_test:3: 100%|| 88/88 [00:06<00:00, 12.88it/s]\n",
      "2024-05-29 15:37:19,341 - {'Epoch': 3, 'HR@5': '0.0194', 'NDCG@5': '0.0119', 'HR@10': '0.0337', 'NDCG@10': '0.0165', 'HR@20': '0.0525', 'NDCG@20': '0.0212'}\n",
      "2024-05-29 15:37:19,341 - {'Epoch': 3, 'HR@5': '0.0194', 'NDCG@5': '0.0119', 'HR@10': '0.0337', 'NDCG@10': '0.0165', 'HR@20': '0.0525', 'NDCG@20': '0.0212'}\n",
      "2024-05-29 15:37:19,349 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:37:19,349 - Validation score increased.  Saving model ...\n",
      "Mode_train:4: 100%|| 587/587 [01:29<00:00,  6.56it/s]\n",
      "2024-05-29 15:38:48,814 - {'epoch': 4, 'rec_loss': '0.8939'}\n",
      "2024-05-29 15:38:48,814 - {'epoch': 4, 'rec_loss': '0.8939'}\n",
      "Mode_test:4: 100%|| 88/88 [00:06<00:00, 12.74it/s]\n",
      "2024-05-29 15:38:56,248 - {'Epoch': 4, 'HR@5': '0.0207', 'NDCG@5': '0.0126', 'HR@10': '0.0345', 'NDCG@10': '0.0171', 'HR@20': '0.0559', 'NDCG@20': '0.0224'}\n",
      "2024-05-29 15:38:56,248 - {'Epoch': 4, 'HR@5': '0.0207', 'NDCG@5': '0.0126', 'HR@10': '0.0345', 'NDCG@10': '0.0171', 'HR@20': '0.0559', 'NDCG@20': '0.0224'}\n",
      "2024-05-29 15:38:56,259 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:38:56,259 - Validation score increased.  Saving model ...\n",
      "Mode_train:5: 100%|| 587/587 [01:30<00:00,  6.49it/s]\n",
      "2024-05-29 15:40:26,727 - {'epoch': 5, 'rec_loss': '0.8482'}\n",
      "2024-05-29 15:40:26,727 - {'epoch': 5, 'rec_loss': '0.8482'}\n",
      "Mode_test:5: 100%|| 88/88 [00:07<00:00, 12.19it/s]\n",
      "2024-05-29 15:40:34,479 - {'Epoch': 5, 'HR@5': '0.0197', 'NDCG@5': '0.0124', 'HR@10': '0.0343', 'NDCG@10': '0.0171', 'HR@20': '0.0553', 'NDCG@20': '0.0224'}\n",
      "2024-05-29 15:40:34,479 - {'Epoch': 5, 'HR@5': '0.0197', 'NDCG@5': '0.0124', 'HR@10': '0.0343', 'NDCG@10': '0.0171', 'HR@20': '0.0553', 'NDCG@20': '0.0224'}\n",
      "2024-05-29 15:40:34,488 - EarlyStopping counter: 1 out of 10\n",
      "2024-05-29 15:40:34,488 - EarlyStopping counter: 1 out of 10\n",
      "Mode_train:6: 100%|| 587/587 [01:30<00:00,  6.46it/s]\n",
      "2024-05-29 15:42:05,410 - {'epoch': 6, 'rec_loss': '0.8075'}\n",
      "2024-05-29 15:42:05,410 - {'epoch': 6, 'rec_loss': '0.8075'}\n",
      "Mode_test:6: 100%|| 88/88 [00:06<00:00, 13.58it/s]\n",
      "2024-05-29 15:42:12,415 - {'Epoch': 6, 'HR@5': '0.0245', 'NDCG@5': '0.0152', 'HR@10': '0.0405', 'NDCG@10': '0.0203', 'HR@20': '0.0632', 'NDCG@20': '0.0260'}\n",
      "2024-05-29 15:42:12,415 - {'Epoch': 6, 'HR@5': '0.0245', 'NDCG@5': '0.0152', 'HR@10': '0.0405', 'NDCG@10': '0.0203', 'HR@20': '0.0632', 'NDCG@20': '0.0260'}\n",
      "2024-05-29 15:42:12,423 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:42:12,423 - Validation score increased.  Saving model ...\n",
      "Mode_train:7: 100%|| 587/587 [01:30<00:00,  6.50it/s]\n",
      "2024-05-29 15:43:42,754 - {'epoch': 7, 'rec_loss': '0.7750'}\n",
      "2024-05-29 15:43:42,754 - {'epoch': 7, 'rec_loss': '0.7750'}\n",
      "Mode_test:7: 100%|| 88/88 [00:06<00:00, 13.29it/s]\n",
      "2024-05-29 15:43:49,902 - {'Epoch': 7, 'HR@5': '0.0233', 'NDCG@5': '0.0146', 'HR@10': '0.0410', 'NDCG@10': '0.0202', 'HR@20': '0.0661', 'NDCG@20': '0.0265'}\n",
      "2024-05-29 15:43:49,902 - {'Epoch': 7, 'HR@5': '0.0233', 'NDCG@5': '0.0146', 'HR@10': '0.0410', 'NDCG@10': '0.0202', 'HR@20': '0.0661', 'NDCG@20': '0.0265'}\n",
      "2024-05-29 15:43:49,909 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:43:49,909 - Validation score increased.  Saving model ...\n",
      "Mode_train:8: 100%|| 587/587 [01:30<00:00,  6.46it/s]\n",
      "2024-05-29 15:45:20,811 - {'epoch': 8, 'rec_loss': '0.7461'}\n",
      "2024-05-29 15:45:20,811 - {'epoch': 8, 'rec_loss': '0.7461'}\n",
      "Mode_test:8: 100%|| 88/88 [00:06<00:00, 12.78it/s]\n",
      "2024-05-29 15:45:28,229 - {'Epoch': 8, 'HR@5': '0.0253', 'NDCG@5': '0.0160', 'HR@10': '0.0411', 'NDCG@10': '0.0211', 'HR@20': '0.0685', 'NDCG@20': '0.0280'}\n",
      "2024-05-29 15:45:28,229 - {'Epoch': 8, 'HR@5': '0.0253', 'NDCG@5': '0.0160', 'HR@10': '0.0411', 'NDCG@10': '0.0211', 'HR@20': '0.0685', 'NDCG@20': '0.0280'}\n",
      "2024-05-29 15:45:28,238 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:45:28,238 - Validation score increased.  Saving model ...\n",
      "Mode_train:9: 100%|| 587/587 [01:35<00:00,  6.18it/s]\n",
      "2024-05-29 15:47:03,287 - {'epoch': 9, 'rec_loss': '0.7241'}\n",
      "2024-05-29 15:47:03,287 - {'epoch': 9, 'rec_loss': '0.7241'}\n",
      "Mode_test:9: 100%|| 88/88 [00:07<00:00, 12.56it/s]\n",
      "2024-05-29 15:47:10,826 - {'Epoch': 9, 'HR@5': '0.0278', 'NDCG@5': '0.0179', 'HR@10': '0.0456', 'NDCG@10': '0.0235', 'HR@20': '0.0729', 'NDCG@20': '0.0304'}\n",
      "2024-05-29 15:47:10,826 - {'Epoch': 9, 'HR@5': '0.0278', 'NDCG@5': '0.0179', 'HR@10': '0.0456', 'NDCG@10': '0.0235', 'HR@20': '0.0729', 'NDCG@20': '0.0304'}\n",
      "2024-05-29 15:47:10,835 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:47:10,835 - Validation score increased.  Saving model ...\n",
      "2024-05-29 15:47:10,839 - ---------------Test Score---------------\n",
      "2024-05-29 15:47:10,839 - ---------------Test Score---------------\n",
      "Mode_test:0: 100%|| 88/88 [00:06<00:00, 12.93it/s]\n",
      "2024-05-29 15:47:18,178 - {'Epoch': 0, 'HR@5': '0.0216', 'NDCG@5': '0.0136', 'HR@10': '0.0360', 'NDCG@10': '0.0182', 'HR@20': '0.0580', 'NDCG@20': '0.0237'}\n",
      "2024-05-29 15:47:18,178 - {'Epoch': 0, 'HR@5': '0.0216', 'NDCG@5': '0.0136', 'HR@10': '0.0360', 'NDCG@10': '0.0182', 'HR@20': '0.0580', 'NDCG@20': '0.0237'}\n",
      "2024-05-29 15:47:18,185 - sasrec_model\n",
      "2024-05-29 15:47:18,185 - sasrec_model\n",
      "2024-05-29 15:47:18,185 - {'Epoch': 0, 'HR@5': '0.0216', 'NDCG@5': '0.0136', 'HR@10': '0.0360', 'NDCG@10': '0.0182', 'HR@20': '0.0580', 'NDCG@20': '0.0237'}\n",
      "2024-05-29 15:47:18,185 - {'Epoch': 0, 'HR@5': '0.0216', 'NDCG@5': '0.0136', 'HR@10': '0.0360', 'NDCG@10': '0.0182', 'HR@20': '0.0580', 'NDCG@20': '0.0237'}\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from model.sasrec import SASRecModel\n",
    "from trainers import Trainer\n",
    "from utils import EarlyStopping, check_path, set_seed, set_logger\n",
    "from dataset import get_seq_dic, get_dataloder, get_rating_matrix\n",
    "\n",
    "# Set up arguments\n",
    "class Args:\n",
    "    data_dir = \"./data/\"\n",
    "    output_dir = \"output/\"\n",
    "    data_name = \"Beauty\"\n",
    "    do_eval = False\n",
    "    load_model = None\n",
    "    train_name = \"sasrec_model\"\n",
    "    num_items = 10\n",
    "    num_users = 10\n",
    "    lr = 0.001\n",
    "    batch_size = 256\n",
    "    epochs = 10\n",
    "    no_cuda = False\n",
    "    log_freq = 1\n",
    "    patience = 10\n",
    "    num_workers = 0  # Set num_workers to 0 to avoid BrokenPipeError on Windows\n",
    "    seed = 42\n",
    "    weight_decay = 0.0\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "    gpu_id = \"0\"\n",
    "    variance = 5\n",
    "    model_type = 'sasrec'\n",
    "    max_seq_length = 50\n",
    "    hidden_size = 64\n",
    "    num_hidden_layers = 2\n",
    "    hidden_act = \"gelu\"\n",
    "    num_attention_heads = 2\n",
    "    attention_probs_dropout_prob = 0.5\n",
    "    hidden_dropout_prob = 0.5\n",
    "    initializer_range = 0.02\n",
    "\n",
    "args = Args()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Initialize logger\n",
    "    log_path = os.path.join(args.output_dir, args.train_name + '.log')\n",
    "    logger = set_logger(log_path)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    check_path(args.output_dir)\n",
    "\n",
    "    # Set CUDA environment\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    args.cuda_condition = torch.cuda.is_available() and not args.no_cuda\n",
    "\n",
    "    # Load data\n",
    "    seq_dic, max_item, num_users = get_seq_dic(args)\n",
    "    args.item_size = max_item + 1\n",
    "    args.num_users = num_users + 1\n",
    "\n",
    "    # Prepare checkpoint paths\n",
    "    args.checkpoint_path = os.path.join(args.output_dir, args.train_name + '.pt')\n",
    "    args.same_target_path = os.path.join(args.data_dir, args.data_name+'_same_target.npy')\n",
    "\n",
    "    # Load dataloaders\n",
    "    train_dataloader, eval_dataloader, test_dataloader = get_dataloder(args, seq_dic)\n",
    "\n",
    "    # Initialize and log model\n",
    "    logger.info(str(args))\n",
    "    model = SASRecModel(args=args)\n",
    "    logger.info(model)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(model, train_dataloader, eval_dataloader, test_dataloader, args, logger)\n",
    "\n",
    "    # Generate rating matrices for evaluation\n",
    "    args.valid_rating_matrix, args.test_rating_matrix = get_rating_matrix(args.data_name, seq_dic, max_item)\n",
    "\n",
    "    # Training and evaluation\n",
    "    if args.do_eval:\n",
    "        if args.load_model is None:\n",
    "            logger.info(f\"No model input!\")\n",
    "            exit(0)\n",
    "        else:\n",
    "            args.checkpoint_path = os.path.join(args.output_dir, args.load_model + '.pt')\n",
    "            trainer.load(args.checkpoint_path)\n",
    "            logger.info(f\"Load model from {args.checkpoint_path} for test!\")\n",
    "            scores, result_info = trainer.test(0)\n",
    "    else:\n",
    "        early_stopping = EarlyStopping(args.checkpoint_path, logger=logger, patience=args.patience, verbose=True)\n",
    "        for epoch in range(args.epochs):\n",
    "            trainer.train(epoch)\n",
    "            scores, _ = trainer.valid(epoch)\n",
    "            # evaluate on MRR\n",
    "            early_stopping(np.array(scores[-1:]), trainer.model)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        logger.info(\"---------------Test Score---------------\")\n",
    "        trainer.model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "        scores, result_info = trainer.test(0)\n",
    "\n",
    "    logger.info(args.train_name)\n",
    "    logger.info(result_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052cacb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Indices: tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
      "         14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "         28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,\n",
      "         42,  43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,\n",
      "         56,  57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,\n",
      "         70,  71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,\n",
      "         84,  85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,\n",
      "         98,  99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111,\n",
      "        112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "        126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139,\n",
      "        140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153,\n",
      "        154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167,\n",
      "        168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
      "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195,\n",
      "        196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209,\n",
      "        210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223,\n",
      "        224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237,\n",
      "        238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251,\n",
      "        252, 253, 254, 255])\n",
      "Input IDs: tensor([[   0,    0,    0,  ...,    2,    3,    4],\n",
      "        [   0,    0,    0,  ...,    9,   10,    4],\n",
      "        [   0,    0,    0,  ...,   16,   17,   18],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ..., 2491, 2492, 2493],\n",
      "        [   0,    0,    0,  ...,  545, 2109, 2496],\n",
      "        [   0,    0,    0,  ...,  532, 1618, 2501]])\n",
      "Answers: tensor([   5,   11,   19,   24,   32,   49,    4,   59,   83,   91,   97,   28,\n",
      "         108,  116,  122,  126,  130,  135,  143,  179,  185,  196,  165,  213,\n",
      "         233,  240,  317,  325,  340,  214,  166,  424,  434,  443,  456,  472,\n",
      "         477,  482,  487,  497,  501,  509,  460,  564,  569,  573,  580,  585,\n",
      "         594,   70,  315,  624,  631,  644,  651,  552,  661,  669,  675,  682,\n",
      "         686,  691,  666,  720,  728,  732,  737,  743,  565,  774,  778,  780,\n",
      "          75,  666,  666,  801,  669,  809,  824,  834,  858,  865,  877,  885,\n",
      "         894,  901,  337,  963,  967,  685,  889,  984,  993, 1010, 1034, 1079,\n",
      "        1083, 1086, 1092, 1100, 1107, 1121, 1112, 1132,  844,  620,  961,  774,\n",
      "         693, 1189, 1207, 1210, 1109, 1239, 1243, 1248, 1252, 1275, 1301, 1306,\n",
      "        1309,  963, 1318, 1322, 1201, 1335, 1336,  491,  170, 1352, 1357, 1374,\n",
      "        1376,  578,  883,  170, 1440, 1445, 1450, 1187,   68, 1461, 1356, 1469,\n",
      "        1474, 1482,   25, 1489, 1494, 1498,   20, 1522, 1527, 1525, 1538, 1551,\n",
      "        1562, 1568,  309, 1575, 1584, 1588, 1564, 1601, 1605,  192, 1625, 1653,\n",
      "        1684, 1687, 1072, 1699, 1705, 1715,  688,  504, 1729, 1054, 1851, 1484,\n",
      "        1861, 1869,  103, 1884, 1889, 1895, 1564, 1905,  319, 1915, 1921, 1926,\n",
      "        1929, 1935, 1564,  103, 1275, 1392, 1992, 1303, 2026, 2049, 2063, 2066,\n",
      "        2079, 2088, 2091, 2127, 2128, 1408, 2134, 2138,  851, 2149, 2153, 2157,\n",
      "        2163, 1148, 2173, 2183, 2190,  374, 2194, 1933, 2275, 1201, 1836, 2290,\n",
      "        1148, 2312, 2319, 2321, 2328,   46, 2340, 1356,  336, 2343, 2395,  129,\n",
      "        1606, 2412, 1882,  392, 2448, 2456,   24, 2464, 2468, 1050, 1618, 1487,\n",
      "        2489, 1344, 2497, 2502])\n",
      "--------------------------------------------------\n",
      "Batch 2:\n",
      "Indices: tensor([256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269,\n",
      "        270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283,\n",
      "        284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297,\n",
      "        298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311,\n",
      "        312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325,\n",
      "        326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339,\n",
      "        340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353,\n",
      "        354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367,\n",
      "        368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381,\n",
      "        382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395,\n",
      "        396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409,\n",
      "        410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423,\n",
      "        424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437,\n",
      "        438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451,\n",
      "        452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465,\n",
      "        466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479,\n",
      "        480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493,\n",
      "        494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507,\n",
      "        508, 509, 510, 511])\n",
      "Input IDs: tensor([[   0,    0,    0,  ..., 1112, 2505, 2506],\n",
      "        [   0,    0,    0,  ..., 1322, 1792, 2510],\n",
      "        [   0,    0,    0,  ..., 2519, 2520, 2521],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ..., 4074,  327, 4075],\n",
      "        [   0,    0,    0,  ..., 1334, 3769, 1799],\n",
      "        [   0,    0,    0,  ..., 1096, 4088, 4034]])\n",
      "Answers: tensor([2507, 2511, 2522, 2523, 2538, 2522,  990, 1948,  598,  961, 2624, 2635,\n",
      "        2638, 2643, 1879, 2651, 2658, 2663,  491, 2672, 2680, 2684, 1144, 1131,\n",
      "        2698,  417, 2725, 2735, 2642, 2741, 2745, 2751,  925, 2129, 2766, 2771,\n",
      "          33, 1535,   81, 2782, 2083, 1520, 1280, 2795, 2798, 2802, 2826, 2831,\n",
      "        2833, 1535, 1363, 1682,  737, 2859,  714, 2871, 2876, 2882, 2885, 1342,\n",
      "        2888, 2899, 2903, 2906, 2910, 2914, 2926, 2930, 2932, 2937,  169, 2943,\n",
      "         853, 1019, 1533, 2173, 2963, 2972, 1401, 2979, 2984,  261,  333, 3016,\n",
      "        3040, 3043, 2140, 1130, 3053, 3017, 2553, 3063, 3069, 3074, 1333, 3093,\n",
      "        1121, 3102,  454, 3109, 3125,   65, 3078, 3138, 3143, 3154, 3161,  866,\n",
      "        3175, 3100, 1205, 3100,  858, 3196, 3201, 3100, 2189,  337, 3217, 2295,\n",
      "        3224,  533,  855, 3257, 1786, 3262, 3264,  113, 3267, 3271, 3282,  269,\n",
      "        3295, 3298, 3301, 1962, 1187, 3170,  343,  417, 3339, 3343, 3352, 3354,\n",
      "        1881, 2301, 3373, 3412, 3415, 1850, 3434, 1638, 3447, 3468, 3480, 2891,\n",
      "        3494, 3562, 1181, 3567, 1121, 3574, 3576,  813, 3588, 2311,  836, 3639,\n",
      "        1156, 2456, 3650, 3654, 2650, 3659,  532, 1918, 3663, 3671, 1400, 1813,\n",
      "          85, 3704, 2238, 3739, 3663, 2507, 1178,   53, 3747, 3751, 1984, 3761,\n",
      "        2856, 1458, 2265,  263, 2197, 3787, 1135, 3794, 1801, 3812, 3818, 1373,\n",
      "        3823,  686, 3829, 3833, 1463, 3841,  962, 3858, 2128, 1865,  773, 3878,\n",
      "        3884, 3107, 1308, 3899, 3903, 3915,  984, 3926, 3932,  396, 3947,  885,\n",
      "        3958, 1206, 3967, 3974, 3999, 1935, 1825, 1532, 3970, 4013, 4016, 1775,\n",
      "        4021, 4027, 4031, 4035,  603, 1436, 4055, 4057, 2265, 1674, 3164, 1450,\n",
      "        4072, 1096, 1096, 4089])\n",
      "--------------------------------------------------\n",
      "Batch 3:\n",
      "Indices: tensor([512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525,\n",
      "        526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539,\n",
      "        540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553,\n",
      "        554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567,\n",
      "        568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581,\n",
      "        582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595,\n",
      "        596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609,\n",
      "        610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623,\n",
      "        624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637,\n",
      "        638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651,\n",
      "        652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665,\n",
      "        666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679,\n",
      "        680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693,\n",
      "        694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707,\n",
      "        708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721,\n",
      "        722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735,\n",
      "        736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749,\n",
      "        750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763,\n",
      "        764, 765, 766, 767])\n",
      "Input IDs: tensor([[   0,    0,    0,  ..., 3146,  343,  523],\n",
      "        [   0,    0,    0,  ..., 1674, 4103, 3821],\n",
      "        [   0,    0,    0,  ..., 4105,  737,  523],\n",
      "        ...,\n",
      "        [   0,    0,    0,  ...,  178, 4081,  648],\n",
      "        [   0,    0,    0,  ..., 1483, 5237, 5238],\n",
      "        [   0,    0,    0,  ..., 5240, 3983, 4287]])\n",
      "Answers: tensor([4091, 3031, 4106, 1164, 1527, 4121,  588, 4140, 4143, 4154, 4167, 4170,\n",
      "        4181, 1935, 1225, 4190, 2112, 4198, 4202, 4208, 1674, 4214, 4219, 1478,\n",
      "        2653, 1356, 4251, 4252, 3061, 4256, 3429, 2640, 3242, 4264, 3850, 2020,\n",
      "        4286,  752, 1398, 3440, 4296, 4300, 3445, 4309, 4315, 4320,  932, 4324,\n",
      "        1262, 1920, 4353, 1537, 4368, 3097, 4388,  323,  794, 4396, 1588, 2728,\n",
      "          95, 4409,  671, 1674, 3517, 4417,  171, 4429, 3962, 4467, 4471, 4486,\n",
      "        1674, 3106, 4500, 4507, 3756, 4514, 4521, 4524, 1356, 4530, 1332, 1283,\n",
      "        1727,  535, 4549, 4550, 1460, 3947, 4557, 2204, 1019, 4573, 1292,  770,\n",
      "         248, 3250, 3059,  857,  866, 1674, 4588,   87, 4597, 4610, 4618, 1935,\n",
      "         634, 2080, 4631, 4289,  563, 4638, 1526,   41, 4466, 4648,  544, 1615,\n",
      "        4660, 4673, 2149, 1664,  524, 2316, 4682, 4683,   39, 4687, 3983, 4375,\n",
      "         685, 4696, 4699, 3293, 3678,  226, 4725, 1237, 2642,  898, 4773, 4782,\n",
      "        4786, 1817,  978, 1127, 2333, 3998, 4806,  382, 4808, 2114, 4815, 1209,\n",
      "        4644, 4823, 2105,  978, 3266,  704, 2284, 2945,  959, 4844,  978, 4851,\n",
      "        4854,   78, 4862, 3983, 4868,  717, 4880, 4196,  978, 4887, 4889, 3584,\n",
      "        1452,  176, 1034, 4899, 4907, 2111, 2002,  888, 4548, 3744,  195, 1056,\n",
      "        2301, 4962, 4964, 4971, 1622, 2693, 2105, 2306, 4710, 2518,  335, 4985,\n",
      "        2304, 2123, 3017, 4994, 4997, 4999, 1741, 4390, 3099, 2162, 5004, 5007,\n",
      "        5011, 4798, 1306,  788, 5055, 1747, 2693,  788, 4720, 1356, 5071, 5041,\n",
      "        3814,   14, 4690, 5115, 4690,  574, 4233, 5186, 3657, 1772,  789, 5194,\n",
      "         170, 2672, 5208, 2321, 5060, 5222,  609, 5225, 2278, 3046,  339, 5231,\n",
      "        4217, 2080,  789, 3330])\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_batches_to_show = 3  # 확인하고자 하는 배치의 수\n",
    "\n",
    "for i, batch in enumerate(test_dataloader):\n",
    "    if i >= num_batches_to_show:\n",
    "        break  # 지정된 수의 배치를 확인한 후 종료\n",
    "    indices, input_ids, answers, _, _ = batch\n",
    "    print(f\"Batch {i+1}:\")\n",
    "    print(\"Indices:\", indices)\n",
    "    print(\"Input IDs:\", input_ids)\n",
    "    print(\"Answers:\", answers)\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58969a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 50])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.0197, 0.0198, 0.0199, 0.0196, 0.0199, 0.0197, 0.0200, 0.0199, 0.0195,\n",
       "        0.0201, 0.0205, 0.0199, 0.0198, 0.0207, 0.0205, 0.0195, 0.0213, 0.0209,\n",
       "        0.0200, 0.0204, 0.0205, 0.0208, 0.0204, 0.0203, 0.0196, 0.0209, 0.0209,\n",
       "        0.0202, 0.0205, 0.0200, 0.0201, 0.0201, 0.0208, 0.0196, 0.0198, 0.0197,\n",
       "        0.0195, 0.0185, 0.0192, 0.0197, 0.0198, 0.0196, 0.0197, 0.0196, 0.0201,\n",
       "        0.0195, 0.0188, 0.0199, 0.0204, 0.0201])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_attention_weights(model, input_ids):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        extended_attention_mask = model.get_attention_mask(input_ids)\n",
    "        sequence_emb = model.add_position_embedding(input_ids)\n",
    "        item_encoded_layers = model.item_encoder(sequence_emb, extended_attention_mask, output_all_encoded_layers=True)\n",
    "        attention_weights = item_encoded_layers[-1]  # Extract the attention weights from the last layer\n",
    "        #attention_probs = torch.nn.functional.softmax(attention_weights, dim=-1)\n",
    "    return attention_weights\n",
    "\n",
    "# Example usage with a batch from the test dataloader\n",
    "batch = next(iter(test_dataloader))\n",
    "input_ids = batch[1]\n",
    "attention_weights = get_attention_weights(model, input_ids)\n",
    "mean_attention_weights = torch.mean(attention_weights, dim=-1)\n",
    "print(mean_attention_weights.size())\n",
    "attention_probs = torch.nn.functional.softmax(mean_attention_weights, dim=-1)\n",
    "attention_probs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fa849a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
