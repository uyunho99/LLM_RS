{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from model.sasrec import SASRecModel\n",
    "from trainers import Trainer\n",
    "from utils import EarlyStopping, check_path, set_seed, set_logger\n",
    "from dataset import get_seq_dic, get_dataloder, get_rating_matrix\n",
    "import pandas as pd\n",
    "\n",
    "# Set up arguments\n",
    "class Args:\n",
    "    data_dir = \"./data/\"\n",
    "    output_dir = \"output/\"\n",
    "    data_name = \"input_test-Copy1\"\n",
    "    do_eval = False\n",
    "    load_model = None\n",
    "    train_name = \"sasrec_model\"\n",
    "    num_items = 10\n",
    "    num_users = 10\n",
    "    lr = 0.001\n",
    "    batch_size = 256\n",
    "    epochs = 10\n",
    "    no_cuda = False\n",
    "    log_freq = 1\n",
    "    patience = 2\n",
    "    num_workers = 0  # Set num_workers to 0 to avoid BrokenPipeError on Windows\n",
    "    seed = 42\n",
    "    weight_decay = 0.0\n",
    "    adam_beta1 = 0.9\n",
    "    adam_beta2 = 0.999\n",
    "    gpu_id = \"0\"\n",
    "    variance = 5\n",
    "    # model_type = 'bert4rec'\n",
    "    model_type = 'sasrec_model'\n",
    "    max_seq_length = 15\n",
    "    hidden_size = 64\n",
    "    num_hidden_layers = 2\n",
    "    hidden_act = \"gelu\"\n",
    "    num_attention_heads = 2\n",
    "    attention_probs_dropout_prob = 0.5\n",
    "    hidden_dropout_prob = 0.5\n",
    "    initializer_range = 0.02\n",
    "    item_size = 10\n",
    "\n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-29 19:01:32,815 - <__main__.Args object at 0x1490212e0>\n",
      "2024-07-29 19:01:32,892 - SASRecModel(\n",
      "  (item_embeddings): Embedding(33, 64, padding_idx=0)\n",
      "  (position_embeddings): Embedding(15, 64)\n",
      "  (LayerNorm): LayerNorm()\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (item_encoder): TransformerEncoder(\n",
      "    (blocks): ModuleList(\n",
      "      (0-1): 2 x TransformerBlock(\n",
      "        (layer): MultiHeadAttention(\n",
      "          (query): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (softmax): Softmax(dim=-1)\n",
      "          (attn_dropout): Dropout(p=0.5, inplace=False)\n",
      "          (dense): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm((64,), eps=1e-12, elementwise_affine=True)\n",
      "          (out_dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (dense_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dense_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "          (LayerNorm): LayerNorm()\n",
      "          (dropout): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "2024-07-29 19:01:33,361 - Total Parameters: 103168\n",
      "Mode_train:0: 100%|| 1/1 [00:00<00:00, 46.88it/s]\n",
      "2024-07-29 19:01:33,393 - {'epoch': 0, 'rec_loss': '1.4375'}\n",
      "Mode_test:0: 100%|| 1/1 [00:00<00:00, 428.78it/s]\n",
      "2024-07-29 19:01:33,398 - {'Epoch': 0, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.6667', 'NDCG@10': '0.2222', 'HR@20': '0.6667', 'NDCG@20': '0.2222'}\n",
      "2024-07-29 19:01:33,399 - Validation score increased.  Saving model ...\n",
      "Mode_train:1: 100%|| 1/1 [00:00<00:00, 221.00it/s]\n",
      "2024-07-29 19:01:33,407 - {'epoch': 1, 'rec_loss': '1.2925'}\n",
      "Mode_test:1: 100%|| 1/1 [00:00<00:00, 443.65it/s]\n",
      "2024-07-29 19:01:33,410 - {'Epoch': 1, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.6667', 'NDCG@10': '0.2163', 'HR@20': '0.6667', 'NDCG@20': '0.2163'}\n",
      "2024-07-29 19:01:33,411 - EarlyStopping counter: 1 out of 2\n",
      "Mode_train:2: 100%|| 1/1 [00:00<00:00, 197.43it/s]\n",
      "2024-07-29 19:01:33,418 - {'epoch': 2, 'rec_loss': '1.3861'}\n",
      "Mode_test:2: 100%|| 1/1 [00:00<00:00, 513.69it/s]\n",
      "2024-07-29 19:01:33,422 - {'Epoch': 2, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.6667', 'NDCG@10': '0.1967', 'HR@20': '1.0000', 'NDCG@20': '0.2738'}\n",
      "2024-07-29 19:01:33,423 - Validation score increased.  Saving model ...\n",
      "Mode_train:3: 100%|| 1/1 [00:00<00:00, 187.62it/s]\n",
      "2024-07-29 19:01:33,431 - {'epoch': 3, 'rec_loss': '1.3481'}\n",
      "Mode_test:3: 100%|| 1/1 [00:00<00:00, 467.70it/s]\n",
      "2024-07-29 19:01:33,434 - {'Epoch': 3, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.3333', 'NDCG@10': '0.1003', 'HR@20': '1.0000', 'NDCG@20': '0.2720'}\n",
      "2024-07-29 19:01:33,435 - EarlyStopping counter: 1 out of 2\n",
      "Mode_train:4: 100%|| 1/1 [00:00<00:00, 239.46it/s]\n",
      "2024-07-29 19:01:33,440 - {'epoch': 4, 'rec_loss': '1.3963'}\n",
      "Mode_test:4: 100%|| 1/1 [00:00<00:00, 467.49it/s]\n",
      "2024-07-29 19:01:33,444 - {'Epoch': 4, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.3333', 'NDCG@10': '0.0964', 'HR@20': '1.0000', 'NDCG@20': '0.2727'}\n",
      "2024-07-29 19:01:33,445 - EarlyStopping counter: 2 out of 2\n",
      "2024-07-29 19:01:33,445 - Early stopping\n",
      "2024-07-29 19:01:33,445 - ---------------Test Score---------------\n",
      "Mode_test:0: 100%|| 1/1 [00:00<00:00, 599.61it/s]\n",
      "2024-07-29 19:01:33,450 - {'Epoch': 0, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.3333', 'NDCG@10': '0.0964', 'HR@20': '1.0000', 'NDCG@20': '0.2507'}\n",
      "2024-07-29 19:01:33,451 - sasrec_model\n",
      "2024-07-29 19:01:33,451 - {'Epoch': 0, 'HR@5': '0.0000', 'NDCG@5': '0.0000', 'HR@10': '0.3333', 'NDCG@10': '0.0964', 'HR@20': '1.0000', 'NDCG@20': '0.2507'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Initialize logger\n",
    "    log_path = os.path.join(args.output_dir, args.train_name + '.log')\n",
    "    logger = set_logger(log_path)\n",
    "\n",
    "    # Set seed for reproducibility\n",
    "    set_seed(args.seed)\n",
    "\n",
    "    # Create output directory if not exists\n",
    "    check_path(args.output_dir)\n",
    "\n",
    "    # Set CUDA environment\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    args.cuda_condition = torch.cuda.is_available() and not args.no_cuda\n",
    "\n",
    "    # Load data\n",
    "    seq_dic, max_item, num_users = get_seq_dic(args)\n",
    "    args.item_size = max_item + 1\n",
    "    args.num_users = num_users + 1\n",
    "\n",
    "    # Prepare checkpoint paths\n",
    "    args.checkpoint_path = os.path.join(args.output_dir, args.train_name + '.pt')\n",
    "    args.same_target_path = os.path.join(args.data_dir, args.data_name+'_same_target.npy')\n",
    "\n",
    "    # Load dataloaders\n",
    "    train_dataloader, eval_dataloader, test_dataloader = get_dataloder(args, seq_dic)\n",
    "\n",
    "    # Initialize and log model\n",
    "    logger.info(str(args))\n",
    "    model = SASRecModel(args=args)\n",
    "    logger.info(model)\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Trainer(model, train_dataloader, eval_dataloader, test_dataloader, args, logger)\n",
    "\n",
    "    # Generate rating matrices for evaluation\n",
    "    args.valid_rating_matrix, args.test_rating_matrix = get_rating_matrix(args.data_name, seq_dic, max_item)\n",
    "\n",
    "    # Training and evaluation\n",
    "    if args.do_eval:\n",
    "        if args.load_model is None:\n",
    "            logger.info(f\"No model input!\")\n",
    "            exit(0)\n",
    "        else:\n",
    "            args.checkpoint_path = os.path.join(args.output_dir, args.load_model + '.pt')\n",
    "            trainer.load(args.checkpoint_path)\n",
    "            logger.info(f\"Load model from {args.checkpoint_path} for test!\")\n",
    "            scores, result_info = trainer.test(0)\n",
    "    else:\n",
    "        early_stopping = EarlyStopping(args.checkpoint_path, logger=logger, patience=args.patience, verbose=True)\n",
    "        for epoch in range(args.epochs):\n",
    "            trainer.train(epoch)\n",
    "            scores, _ = trainer.valid(epoch)\n",
    "            # evaluate on MRR\n",
    "            early_stopping(np.array(scores[-1:]), trainer.model)\n",
    "            if early_stopping.early_stop:\n",
    "                logger.info(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        logger.info(\"---------------Test Score---------------\")\n",
    "        trainer.model.load_state_dict(torch.load(args.checkpoint_path))\n",
    "        scores, result_info = trainer.test(0)\n",
    "\n",
    "    logger.info(args.train_name)\n",
    "    logger.info(result_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input 0: 0 12 13 14 -> Top 20 Predictions: [14, 9, 5, 4, 12, 0, 30, 23, 19, 3, 10, 11, 25, 31, 1, 16, 29, 2, 28, 18]\n",
      "Input 1: 1 31 2 2 -> Top 20 Predictions: [2, 3, 9, 10, 29, 1, 5, 12, 24, 13, 32, 19, 31, 28, 14, 18, 23, 11, 25, 0]\n",
      "Input 2: 2 18 31 32 -> Top 20 Predictions: [32, 9, 3, 2, 11, 0, 30, 29, 23, 31, 14, 19, 10, 12, 28, 13, 5, 17, 26, 24]\n"
     ]
    }
   ],
   "source": [
    "# Standalone predict function\n",
    "def predict(model, input_ids, device):\n",
    "    model.eval()\n",
    "    input_ids = torch.tensor(input_ids, dtype=torch.long).to(device)\n",
    "    with torch.no_grad():\n",
    "        recommend_output = model.forward(input_ids, all_sequence_output=False)\n",
    "        recommend_output = recommend_output[:, -1, :]  # Last item in the sequence\n",
    "\n",
    "        test_item_emb = model.item_embeddings.weight\n",
    "        rating_pred = torch.matmul(recommend_output, test_item_emb.transpose(0, 1))\n",
    "        rating_pred = rating_pred.cpu().data.numpy().copy()\n",
    "\n",
    "        top20_indices = np.argpartition(rating_pred, -20)[:, -20:]\n",
    "        arr_ind = rating_pred[np.arange(len(rating_pred))[:, None], top20_indices]\n",
    "        arr_ind_argsort = np.argsort(arr_ind)[np.arange(len(rating_pred)), ::-1]\n",
    "        top20_indices = top20_indices[np.arange(len(rating_pred))[:, None], arr_ind_argsort]\n",
    "\n",
    "    return top20_indices\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Set CUDA environment\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.gpu_id\n",
    "    args.cuda_condition = torch.cuda.is_available() and not args.no_cuda\n",
    "    device = torch.device(\"cuda\" if args.cuda_condition else \"cpu\")\n",
    "\n",
    "    # Load the checkpoint to get num_items\n",
    "    model_checkpoint_path = os.path.join(args.output_dir, args.train_name + '.pt')\n",
    "    checkpoint = torch.load(model_checkpoint_path, map_location=device)\n",
    "\n",
    "    args.item_size = checkpoint['item_embeddings.weight'].size(0)\n",
    "    \n",
    "    # Initialize and load model\n",
    "    model = SASRecModel(args=args)\n",
    "    model.to(device)\n",
    "    model.load_state_dict(checkpoint)\n",
    "\n",
    "    # Load the input data file\n",
    "    input_file_path = './data/input_test-Copy1.txt'\n",
    "    with open(input_file_path, 'r') as f:\n",
    "        input_data = f.readlines()\n",
    "\n",
    "    # Prepare input for prediction\n",
    "    input_ids = []\n",
    "    for line in input_data:\n",
    "        items = list(map(int, line.strip().split()))\n",
    "        pad_len = args.max_seq_length - len(items)\n",
    "        input_ids.append([0] * pad_len + items)\n",
    "\n",
    "    # Predict top 20 items for each row\n",
    "    predictions = predict(model, input_ids, device)\n",
    "\n",
    "    data = {'Input': [line.strip() for line in input_data], 'Top 20 Predictions': [pred.tolist() for pred in predictions]}\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    output_file_path = './output/predictions.csv'\n",
    "    df.to_csv(output_file_path, index=False)\n",
    "\n",
    "    # Output predictions\n",
    "    for i, pred in enumerate(predictions):\n",
    "        print(f\"Input {i}: {input_data[i].strip()} -> Top 20 Predictions: {pred.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
